{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76063b1e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "AZsq8UWNeoQe",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## **Income Prediction From US Census Adult Income Data**\n",
    "\n",
    "Step into the realm of predictive analysis alongside Mia, the income predictor, in our project, \"Income Prediction From US Census Adult Income Data.\" With Python as her language of choice and a repertoire of powerful algorithms at her disposal, Mia ventures into the world of data to unravel the complexities of income prediction.\n",
    "\n",
    "An individual's annual income is shaped by numerous factors, such as education level, age, gender, and occupation. In this project, we delve into the task of income prediction using the US Adult Income Census dataset. Our primary goal is to accurately predict whether an individual's income falls above or below the $50,000 threshold.\n",
    "\n",
    "The dataset at hand encompasses 16 columns, with the focal point being the \"Income\" field, divided into two classes: <=50K and >50K. With 14 other attributes detailing demographics and individual features, we aim to explore the potential for predicting income levels based on personal information.\n",
    "\n",
    "Employing a suite of algorithms including Logistic Regression, KNN, LDA, Decision Trees, Gaussian NB, Random Forest, and SVC, Mia is equipped to unearth patterns in the data and make precise income predictions based on individual information.\n",
    "\n",
    "Our project isn't merely about predicting incomes; it's a journey that unlocks the potential to understand and forecast an individual's financial standing based on a diverse range of factors.\n",
    "\n",
    "By the end of this project, Mia doesn't just compute predictions; she uncovers the potential to enhance the understanding of income dynamics based on personal attributes.\n",
    "\n",
    "Join Mia on this enlightening journey, where every algorithm and line of code illuminates the path to precise income predictions. Together, we'll unravel the complexities of income prediction and offer valuable insights to empower individuals and guide strategic decisions in various fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a719ef38",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "m5QI7seAfPMp",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Module 1\n",
    "### Task 1: Loading Adult Income Data\n",
    "\n",
    "In this task, we load the adult income data from the 'Income Prediction Adult Data.csv' file into a Pandas DataFrame named 'df.' This step is crucial for our new project, \"Income Prediction From US Census Adult Income Data,\" as it forms the foundation for the data analysis and insights that we aim to derive from the income dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600169ce",
   "metadata": {
    "id": "kuOC3Imi0F1G"
   },
   "outputs": [],
   "source": [
    "#--- Import Pandas ---\n",
    "\n",
    "#--- Read in dataset(Income Prediction Adult Data.csv) ----\n",
    "df = ...\n",
    "\n",
    "#--- Inspect data ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02fce76",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "XOqbICrtfsxG",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Task 2: Identifying Null Values in Adult Income Data\n",
    "\n",
    "In this task, we identify and count the null values within the 'df' dataset. Recognizing null values is crucial to understand the completeness of the dataset. This process helps in determining whether any missing values exist within the data. Addressing or imputing null values is essential for ensuring accurate statistical analyses and model building for income prediction based on the US Census adult income data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118317fb",
   "metadata": {
    "id": "K4w9tjrX0KT3"
   },
   "outputs": [],
   "source": [
    "# --- WRITE YOUR CODE FOR MODULE 1 TASK 2 ---\n",
    "sumofnull = ...\n",
    "\n",
    "#--- Inspect data ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd88a0e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "cDv261xxf0lD",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Task 3: Identifying Data Types in Adult Income Data\n",
    "\n",
    "In this task, we determine the data types of the columns in the 'df' dataset. Understanding the data types is crucial for data analysis and preprocessing. This information aids in selecting appropriate statistical methods and feature engineering techniques that are relevant for the income prediction analysis based on the US Census adult income data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a85d126",
   "metadata": {
    "id": "c14S-PHx0KW2"
   },
   "outputs": [],
   "source": [
    "# --- WRITE YOUR CODE FOR MODULE 1 TASK 3 ---\n",
    "dtype = ...\n",
    "\n",
    "#--- Inspect data ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6f88fe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "lTsP9cudf83Z",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Task 4: Categorizing Features in Adult Income Data\n",
    "\n",
    "In this task, we categorize features within the 'df' dataset into numerical and categorical groups. Identifying numeric and categorical columns helps in defining how different features will be handled during data preprocessing and model building for income prediction based on the US Census adult income data. This categorization is essential for selecting appropriate statistical methods and preprocessing steps tailored for different types of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f8de18",
   "metadata": {
    "id": "iOSox-CD0KZc"
   },
   "outputs": [],
   "source": [
    "# --- WRITE YOUR CODE FOR MODULE 1 TASK 4 ---\n",
    "numeric_features = ...\n",
    "cat_features = ...\n",
    "#--- Inspect data ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa30148",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "CdyI0pQGgWW-",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Task 5: Handling Missing Values in Adult Income Data\n",
    "\n",
    "In this task, a function named 'replace_missing_values' is utilized to replace missing values denoted as '?' in the 'workclass', 'occupation', and 'native.country' columns. By replacing these missing values with a defined 'Unknown' string or a specific country ('United-States'), this process helps in handling missing or unknown data within the dataset for a more accurate and comprehensive analysis for income prediction using the US Census adult income data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ada563",
   "metadata": {
    "id": "EdocvvrR0Kbk"
   },
   "outputs": [],
   "source": [
    "# --- WRITE YOUR CODE FOR MODULE 1 TASK 5 ---\n",
    "#df = ...\n",
    "\n",
    "#--- Inspect data ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf0c6ea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "E_liRyeRght6",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Task 6: Mapping Income Categories in Adult Income Data\n",
    "\n",
    "In this task, a dictionary 'income_map' is created to map income categories represented as '<=50K' and '>50K' to numerical values 0 and 1, respectively, within the 'income' column. This mapping is essential for creating a binary classification target variable, enabling predictive analysis for income levels in the US Census adult income data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe0f68c",
   "metadata": {
    "id": "7wui8TtA0pQJ"
   },
   "outputs": [],
   "source": [
    "# --- WRITE YOUR CODE FOR MODULE 1 TASK 6 ---\n",
    "#df = ...\n",
    "\n",
    "#--- Inspect data ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864d4465",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "hikSnHwYg3mQ",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Module 2\n",
    "### Task 1: Exploring Correlations in Adult Income Data\n",
    "\n",
    "This task involves generating a heatmap using Seaborn to visualize the correlation matrix among the numerical features specified in the 'numeric_features' list within the 'df' dataset. This heatmap provides a visual representation of how strongly each numerical feature correlates with one another. Understanding these correlations is vital for feature selection and model building in the analysis of income prediction based on the US Census adult income data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3e51c8",
   "metadata": {
    "id": "LPeB7zo20pSx"
   },
   "outputs": [],
   "source": [
    "#--- Import matplotlib and  seaborn---\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 2 TASK 1 ---\n",
    "corr_data = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6671f2b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "IDMcOWghhDfi",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Task 2: Visualizing Income Distribution\n",
    "\n",
    "This task involves creating a count plot using Seaborn to illustrate the distribution of income levels within the 'income' column of the 'df' dataset. This plot helps visualize the distribution of income categories (<=50K and >50K) in the US Census adult income data. Understanding this distribution is crucial for understanding the dataset's class balance, an essential factor for accurate model training and prediction in income analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f44c5c1",
   "metadata": {
    "id": "v4n8u4L20pVk"
   },
   "outputs": [],
   "source": [
    "# --- WRITE YOUR CODE FOR MODULE 2 TASK 2 ---\n",
    "income_ax = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b58762",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "DT_vq8ashL9F",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Task 3: Comparing Education and Income\n",
    "This task involves using Seaborn's catplot to create a bar chart to compare the relationship between education (represented by 'education.num') and income ('income') within the 'df' dataset. The visualization helps understand how income levels vary concerning different education levels, providing insights into potential trends or differences based on education in the US Census adult income data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c38a6ba",
   "metadata": {
    "id": "2tCJ4UOL0pYA"
   },
   "outputs": [],
   "source": [
    "# --- WRITE YOUR CODE FOR MODULE 2 TASK 3 ---\n",
    "catplt_edu = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643ef338",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "eNSlbarIhgbz",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Task 4: Analyzing Income and Weekly Working Hours\n",
    "\n",
    "This task employs Seaborn's catplot to create a bar chart for exploring the relationship between income ('income') and the number of hours worked per week ('hours.per.week') within the 'df' dataset. This visualization helps to understand how income levels vary concerning the hours worked per week, providing insights into potential trends or differences based on working hours in the US Census adult income data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1649bc6b",
   "metadata": {
    "id": "M33b5n3P2IOg"
   },
   "outputs": [],
   "source": [
    "# --- WRITE YOUR CODE FOR MODULE 2 TASK 4 ---\n",
    "catplt_hrs = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7667e66",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "aEtZTF3ohwnS",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Task 5: Comparing Age Distribution by Income Level\n",
    "\n",
    "This task involves utilizing Seaborn and Matplotlib to create a FacetGrid with separate columns for each income level ('<=50K' and '>50K') to depict the distribution of ages within the 'df' dataset. By visualizing age distribution concerning income levels, this plot provides insights into how age factors into income disparities, aiding in the analysis of the US Census adult income data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e71d23",
   "metadata": {
    "id": "xH6NK9Id2IVC"
   },
   "outputs": [],
   "source": [
    "# --- WRITE YOUR CODE FOR MODULE 2 TASK 5 ---\n",
    "hist_age = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19e9682",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "jsij4wyeiB5w",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Task 6: Analyzing Income Based on Relationships\n",
    "\n",
    "This task employs Seaborn's catplot to create a bar chart comparing income levels ('income') with different types of relationships ('relationship') within the 'df' dataset. This visualization aims to understand how income varies concerning various relationships, offering insights into potential income differences among different relationship statuses in the US Census adult income data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaccf6a",
   "metadata": {
    "id": "dTI7-91R2IYI"
   },
   "outputs": [],
   "source": [
    "# --- WRITE YOUR CODE FOR MODULE 2 TASK 6 ---\n",
    "catplt_relat = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99981871",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1iB5Wcp5iMtg",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Task 7: Analyzing Income Based on Gender\n",
    "\n",
    "This task utilizes Seaborn's catplot to create a bar chart comparing income levels ('income') based on gender ('sex') within the 'df' dataset. This visualization aims to understand how income levels differ between genders, providing insights into potential income disparities based on gender in the US Census adult income data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1768d665",
   "metadata": {
    "id": "tLiTw3cp2Iaq"
   },
   "outputs": [],
   "source": [
    "# --- WRITE YOUR CODE FOR MODULE 2 TASK 7 ---\n",
    "catplt_sex = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08513993",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "gTrKCmtiikNc",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Task 8: Analyzing Income Based on Marital Status\n",
    "This task employs Seaborn's catplot to create a bar chart comparing income levels ('income') based on marital status ('marital.status') within the 'df' dataset. This visualization aims to understand how income levels differ across different marital statuses, providing insights into potential income disparities related to marital status in the US Census adult income data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159b6a7c",
   "metadata": {
    "id": "y4XGAdF-2Idr"
   },
   "outputs": [],
   "source": [
    "# --- WRITE YOUR CODE FOR MODULE 2 TASK 8 ---\n",
    "catplt_married  = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096f1c37",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "PIMZ9ceEiu2L",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "### Task 9: Analyzing Income Based on Workclass\n",
    "\n",
    "In this task, Seaborn's catplot is used to create a bar chart comparing income levels ('income') based on different work classes ('workclass') within the 'df' dataset. This visualization aims to understand how income levels differ across various work classes, providing insights into potential income disparities related to different employment categories in the US Census adult income data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbcf21e",
   "metadata": {
    "id": "z7QjQhXe2uDo"
   },
   "outputs": [],
   "source": [
    "# --- WRITE YOUR CODE FOR MODULE 2 TASK 9 ---\n",
    "catplt_wrkcls  = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af1260b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Mh1K4pENkIo4",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Module 3\n",
    "### Task 1: Data Preprocessing for Relationship and Gender\n",
    "\n",
    "This task involves creating a modified 'data' DataFrame by encoding the 'sex' attribute from strings 'Male' and 'Female' to numerical values 0 and 1, respectively. Furthermore, it consolidates the 'marital.status' attribute into two categories 'Married' and 'Single' for improved analysis and replaces these categories with binary values 1 and 0, respectively. This preprocessing is vital for refining and simplifying the relationship and gender attributes to enhance the accuracy and interpretability of the data for further analysis in the US Census adult income data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a9ae50",
   "metadata": {
    "id": "khnKTEi225Nl"
   },
   "outputs": [],
   "source": [
    "# --- WRITE YOUR CODE FOR MODULE 3 TASK 1 ---\n",
    "data  = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eefec4c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "rqE0TyvBk-if",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Task 2: Removing Certain Attributes for Data Simplification\n",
    "\n",
    "This task involves dropping specific columns, including \"workclass\", \"education\", \"occupation\", \"relationship\", \"race\", and \"native.country\" from the 'data' DataFrame. The removal of these columns simplifies the dataset by eliminating non-essential or redundant attributes, focusing the analysis on the more relevant features for the US Census adult income data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4e6346",
   "metadata": {
    "id": "64zZY4Pq25RU"
   },
   "outputs": [],
   "source": [
    "# --- WRITE YOUR CODE FOR MODULE 3 TASK 2 ---\n",
    "#data  = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb865fa6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "UBBbVJrDliCo",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Module 4\n",
    "### Task 1: Data Splitting for Modeling in Adult Income Data\n",
    "\n",
    "This task involves splitting the 'data' DataFrame into training and validation sets for modeling. The feature set 'x' is generated by dropping the 'income' column, while the target variable 'y' consists solely of the 'income' column. Utilizing the train_test_split function from sklearn.model_selection, the data is split into 80% training data ('X_train' and 'Y_train') and 20% validation data ('X_validation' and 'Y_validation'). This step is essential for training and evaluating models in the US Census adult income data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c60e299",
   "metadata": {
    "id": "5ddLDuyC25Uy"
   },
   "outputs": [],
   "source": [
    "#--- Import train_test_split ---\n",
    "# --- WRITE YOUR CODE FOR MODULE 4 TASK 1 ---\n",
    "#X_train, X_validation, Y_train, Y_validation  = ...\n",
    "\n",
    "#--- Inspect data ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391b7cde",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "UydUegIDltNQ",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Task 2: Training and Evaluating Logistic Regression Model\n",
    "\n",
    "This task involves training a Logistic Regression model using the training data 'X_train' and 'Y_train' and then assessing the model's performance using cross-validation with 10 folds. The cross_val_score function from sklearn.model_selection assesses the Logistic Regression model's performance and computes the mean accuracy score over the 10 folds. This evaluation is crucial for understanding the model's predictive capability in the US Census adult income data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa21070",
   "metadata": {
    "id": "BErMP99f3Zp2"
   },
   "outputs": [],
   "source": [
    "#--- Import LogisticRegression ---\n",
    "#--- Import cross_val_score from sklearn.model_selection ---\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 4 TASK 2 ---\n",
    "#lr_mean_score  = ...\n",
    "\n",
    "#--- Inspect data ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435e9d1c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "e62z-nB9l06J",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Task 3: Training and Evaluating Linear Discriminant Analysis Model\n",
    "\n",
    "This task involves training a Linear Discriminant Analysis (LDA) model using the training data 'X_train' and 'Y_train' and then assessing the model's performance via 10-fold cross-validation. The cross_val_score function from sklearn.model_selection is used to evaluate the LDA model's accuracy across the 10 folds. This evaluation is vital for understanding the model's performance in predicting income classes within the US Census adult income data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a7e520",
   "metadata": {
    "id": "U273s4s-3Zsl"
   },
   "outputs": [],
   "source": [
    "#--- Import LinearDiscriminantAnalysis ---\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 4 TASK 3 ---\n",
    "#ldr_mean_score  = ...\n",
    "\n",
    "#--- Inspect data ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed3e578",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "g6MdbbGul8-G",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Task 4: Training and Evaluating K-Nearest Neighbors Classifier\n",
    "\n",
    "This task involves training a K-Nearest Neighbors (KNN) classification model using the training data 'X_train' and 'Y_train'. Subsequently, the model's performance is assessed by utilizing the cross_val_score function from sklearn.model_selection, evaluating the KNN model's accuracy across 10-fold cross-validation. This evaluation is important to gauge the KNN model's predictive performance in determining income classes within the US Census adult income data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1f65fd",
   "metadata": {
    "id": "airR9aJq3ZvI"
   },
   "outputs": [],
   "source": [
    "#--- Import KNeighborsClassifier ---\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 4 TASK 4 ---\n",
    "#knn_mean_score  = ...\n",
    "\n",
    "#--- Inspect data ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e094b6ae",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "dzkt3a4nmLu3",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Task 5: Training and Evaluating Decision Tree Classifier\n",
    "\n",
    "This task involves training a Decision Tree Classifier using the training data 'X_train' and 'Y_train', followed by assessing the model's performance through 10-fold cross-validation. The cross_val_score function from sklearn.model_selection is used to compute the Decision Tree Classifier's mean accuracy across the 10 folds. This evaluation is crucial for understanding the Decision Tree model's performance in predicting income classes within the US Census adult income data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f00cc0",
   "metadata": {
    "id": "lnEWKFeA3Zxy"
   },
   "outputs": [],
   "source": [
    "#--- Import DecisionTreeClassifier ---\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 4 TASK 5 ---\n",
    "#dt_mean_score  = ...\n",
    "\n",
    "#--- Inspect data ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98fb45b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "eeHo6hCUmTkB",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Task 6: Training and Evaluating Gaussian Naive Bayes Classifier\n",
    "\n",
    "This task involves training a Gaussian Naive Bayes (NB) classifier using the training data 'X_train' and 'Y_train', followed by assessing the model's performance via 10-fold cross-validation. The cross_val_score function from sklearn.model_selection is utilized to determine the Gaussian NB model's mean accuracy across the 10 folds. This evaluation is essential for comprehending the model's predictive performance in determining income classes within the US Census adult income data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bf36c7",
   "metadata": {
    "id": "3iXk5AHY3Z0Q"
   },
   "outputs": [],
   "source": [
    "#--- Import GaussianNB ---\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 4 TASK 6 ---\n",
    "#gb_mean_score   = ...\n",
    "\n",
    "#--- Inspect data ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19b0f98",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "IU7Z-vepmbjM",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Task 7: Model Optimization using GridSearchCV\n",
    "\n",
    "In this task, GridSearchCV from sklearn.model_selection is utilized to optimize the Linear Discriminant Analysis (LDA) model's performance. The parameters for 'solver' are specified as 'svd', 'lsqr', and 'eigen'. GridSearchCV performs a search across the defined parameters within a 5-fold cross-validation setup using the training data ('X_train' and 'Y_train'). After the grid search, 'best_params' capture the most optimal parameters, and 'best_score' denotes the highest achieved score among the parameter combinations. Additionally, the 'best_ldr_model' variable holds the optimized LDA model with the best parameters obtained from the grid search, enhancing the model's performance within the US Census adult income data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a848864",
   "metadata": {
    "id": "d63J2gFT3Z3O"
   },
   "outputs": [],
   "source": [
    "#--- Import GridSearchCV ---\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 4 TASK 7 ---\n",
    "#best_score   = ...\n",
    "\n",
    "#--- Inspect data ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9aec0f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "UgveHU6rmphn",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Task 8: Evaluating Model Performance on Validation Data\n",
    "\n",
    "This task involves evaluating the performance of the selected model, identified from previous training assessments, using the validation dataset 'X_validation' and 'Y_validation'. The accuracy_score function from sklearn.metrics determines the accuracy by comparing the predicted values ('y_pred') to the actual values ('Y_validation'). Additionally, the confusion_matrix and classification_report functions from sklearn.metrics are used to generate a confusion matrix and a comprehensive classification report, respectively. These metrics provide insights into the model's predictive accuracy and misclassifications, aiding in assessing the model's performance in predicting income classes within the US Census adult income data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231b4638",
   "metadata": {
    "id": "pZqVA0rw3Z43"
   },
   "outputs": [],
   "source": [
    "#--- Import accuracy_score, confusion_matrix, classification_report from sklearn.metrics ---\n",
    "\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 4 TASK 8 ---\n",
    "accuracy= ...\n",
    "\n",
    "cm= ...\n",
    "\n",
    "cr= ...\n",
    "\n",
    "#--- Inspect data ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c8c856",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "vjV5Mj8sncsK",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Task 9: Evaluating Precision, Recall, and F1-Score\n",
    "\n",
    "This task calculates the precision, recall, and F1-score metrics for the model using the validation dataset. The precision_score, recall_score, and f1_score functions from sklearn.metrics are employed to compute precision, recall, and the F1-score, respectively. These metrics offer insights into the model's precision (accuracy of positive predictions), recall (sensitivity to actual positives), and the balance between precision and recall captured by the F1-score. These calculations further aid in understanding the model's performance in predicting income classes within the US Census adult income data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc426cc",
   "metadata": {
    "id": "EzpklsoV4Acs"
   },
   "outputs": [],
   "source": [
    "#--- Import precision_score, recall_score, f1_score from sklearn.metrics ---\n",
    "\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 4 TASK 9 ---\n",
    "# Calculate precision\n",
    "precision = ...\n",
    "\n",
    "# Calculate recall\n",
    "recall = ...\n",
    "\n",
    "# Calculate F1-score\n",
    "F1_score = ...\n",
    "\n",
    "\n",
    "#precision,recall,F1_score\n",
    "\n",
    "#--- Inspect data ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edd938a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "w3bAi_ePoCVu",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Task 10: Predicting Income Class on New Data\n",
    "\n",
    "This task involves utilizing the best-performing model determined from prior evaluations to predict the income class for new data. The new data, structured as a NumPy array, comprises features related to an individual's characteristics, such as age, fnlwgt, education years, among others. The model (which needs to be replaced by the specific best model selected previously) predicts the income class based on these features. The 'predict' method applies the model to the new data to generate the predicted income class, aiding in understanding how accurately the model can predict income status for a new individual in the context of the US Census adult income data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d719189",
   "metadata": {
    "id": "sBtbWdu64Ago"
   },
   "outputs": [],
   "source": [
    "# --- WRITE YOUR CODE FOR MODULE 4 TASK 10 ---\n",
    "#You need to predict the result by passing the sample data available here to your model to make a prediction.\n",
    "\n",
    "new_data = pd.DataFrame([[74, 88638, 16, 0, 1, 0, 683, 20]],\n",
    "                    columns=['age', 'fnlwgt', 'education.num', 'marital.status', 'sex', 'capital.gain', 'capital.loss', 'hours.per.week'])\n",
    "prediction = ...\n",
    "\n",
    "#--- Inspect data ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55de405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## **Income Prediction From US Census Adult Income Data**\n",
    "\n",
    "Step into the realm of predictive analysis alongside Mia, the income predictor, in our project, \"Income Prediction From US Census Adult Income Data.\" With Python as her language of choice and a repertoire of powerful algorithms at her disposal, Mia ventures into the world of data to unravel the complexities of income prediction.\n",
    "\n",
    "An individual's annual income is shaped by numerous factors, such as education level, age, gender, and occupation. In this project, we delve into the task of income prediction using the US Adult Income Census dataset. Our primary goal is to accurately predict whether an individual's income falls above or below the $50,000 threshold.\n",
    "\n",
    "The dataset at hand encompasses 16 columns, with the focal point being the \"Income\" field, divided into two classes: <=50K and >50K. With 14 other attributes detailing demographics and individual features, we aim to explore the potential for predicting income levels based on personal information.\n",
    "\n",
    "Employing a suite of algorithms including Logistic Regression, KNN, LDA, Decision Trees, Gaussian NB, Random Forest, and SVC, Mia is equipped to unearth patterns in the data and make precise income predictions based on individual information.\n",
    "\n",
    "Our project isn't merely about predicting incomes; it's a journey that unlocks the potential to understand and forecast an individual's financial standing based on a diverse range of factors.\n",
    "\n",
    "By the end of this project, Mia doesn't just compute predictions; she uncovers the potential to enhance the understanding of income dynamics based on personal attributes.\n",
    "\n",
    "Join Mia on this enlightening journey, where every algorithm and line of code illuminates the path to precise income predictions. Together, we'll unravel the complexities of income prediction and offer valuable insights to empower individuals and guide strategic decisions in various fields.\n",
    "\n",
    "## Module 1\n",
    "### Task 1: Loading Adult Income Data\n",
    "\n",
    "In this task, we load the adult income data from the 'Income Prediction Adult Data.csv' file into a Pandas DataFrame named 'df.' This step is crucial for our new project, \"Income Prediction From US Census Adult Income Data,\" as it forms the foundation for the data analysis and insights that we aim to derive from the income dataset.\n",
    "\n",
    "#--- Import Pandas ---\n",
    "\n",
    "#--- Read in dataset(Income Prediction Adult Data.csv) ----\n",
    "df = ...\n",
    "\n",
    "#--- Inspect data ---\n",
    "\n",
    "### Task 2: Identifying Null Values in Adult Income Data\n",
    "\n",
    "In this task, we identify and count the null values within the 'df' dataset. Recognizing null values is crucial to understand the completeness of the dataset. This process helps in determining whether any missing values exist within the data. Addressing or imputing null values is essential for ensuring accurate statistical analyses and model building for income prediction based on the US Census adult income data.\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 1 TASK 2 ---\n",
    "sumofnull = ...\n",
    "\n",
    "#--- Inspect data ---\n",
    "\n",
    "### Task 3: Identifying Data Types in Adult Income Data\n",
    "\n",
    "In this task, we determine the data types of the columns in the 'df' dataset. Understanding the data types is crucial for data analysis and preprocessing. This information aids in selecting appropriate statistical methods and feature engineering techniques that are relevant for the income prediction analysis based on the US Census adult income data.\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 1 TASK 3 ---\n",
    "dtype = ...\n",
    "\n",
    "#--- Inspect data ---\n",
    "\n",
    "### Task 4: Categorizing Features in Adult Income Data\n",
    "\n",
    "In this task, we categorize features within the 'df' dataset into numerical and categorical groups. Identifying numeric and categorical columns helps in defining how different features will be handled during data preprocessing and model building for income prediction based on the US Census adult income data. This categorization is essential for selecting appropriate statistical methods and preprocessing steps tailored for different types of features.\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 1 TASK 4 ---\n",
    "numeric_features = ...\n",
    "cat_features = ...\n",
    "#--- Inspect data ---\n",
    "\n",
    "### Task 5: Handling Missing Values in Adult Income Data\n",
    "\n",
    "In this task, a function named 'replace_missing_values' is utilized to replace missing values denoted as '?' in the 'workclass', 'occupation', and 'native.country' columns. By replacing these missing values with a defined 'Unknown' string or a specific country ('United-States'), this process helps in handling missing or unknown data within the dataset for a more accurate and comprehensive analysis for income prediction using the US Census adult income data.\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 1 TASK 5 ---\n",
    "#df = ...\n",
    "\n",
    "#--- Inspect data ---\n",
    "\n",
    "### Task 6: Mapping Income Categories in Adult Income Data\n",
    "\n",
    "In this task, a dictionary 'income_map' is created to map income categories represented as '<=50K' and '>50K' to numerical values 0 and 1, respectively, within the 'income' column. This mapping is essential for creating a binary classification target variable, enabling predictive analysis for income levels in the US Census adult income data.\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 1 TASK 6 ---\n",
    "#df = ...\n",
    "\n",
    "#--- Inspect data ---\n",
    "\n",
    "## Module 2\n",
    "### Task 1: Exploring Correlations in Adult Income Data\n",
    "\n",
    "This task involves generating a heatmap using Seaborn to visualize the correlation matrix among the numerical features specified in the 'numeric_features' list within the 'df' dataset. This heatmap provides a visual representation of how strongly each numerical feature correlates with one another. Understanding these correlations is vital for feature selection and model building in the analysis of income prediction based on the US Census adult income data.\n",
    "\n",
    "#--- Import matplotlib and  seaborn---\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 2 TASK 1 ---\n",
    "corr_data = ...\n",
    "\n",
    "### Task 2: Visualizing Income Distribution\n",
    "\n",
    "This task involves creating a count plot using Seaborn to illustrate the distribution of income levels within the 'income' column of the 'df' dataset. This plot helps visualize the distribution of income categories (<=50K and >50K) in the US Census adult income data. Understanding this distribution is crucial for understanding the dataset's class balance, an essential factor for accurate model training and prediction in income analysis.\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 2 TASK 2 ---\n",
    "income_ax = ...\n",
    "\n",
    "### Task 3: Comparing Education and Income\n",
    "This task involves using Seaborn's catplot to create a bar chart to compare the relationship between education (represented by 'education.num') and income ('income') within the 'df' dataset. The visualization helps understand how income levels vary concerning different education levels, providing insights into potential trends or differences based on education in the US Census adult income data analysis.\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 2 TASK 3 ---\n",
    "catplt_edu = ...\n",
    "\n",
    "### Task 4: Analyzing Income and Weekly Working Hours\n",
    "\n",
    "This task employs Seaborn's catplot to create a bar chart for exploring the relationship between income ('income') and the number of hours worked per week ('hours.per.week') within the 'df' dataset. This visualization helps to understand how income levels vary concerning the hours worked per week, providing insights into potential trends or differences based on working hours in the US Census adult income data analysis.\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 2 TASK 4 ---\n",
    "catplt_hrs = ...\n",
    "\n",
    "\n",
    "### Task 5: Comparing Age Distribution by Income Level\n",
    "\n",
    "This task involves utilizing Seaborn and Matplotlib to create a FacetGrid with separate columns for each income level ('<=50K' and '>50K') to depict the distribution of ages within the 'df' dataset. By visualizing age distribution concerning income levels, this plot provides insights into how age factors into income disparities, aiding in the analysis of the US Census adult income data.\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 2 TASK 5 ---\n",
    "hist_age = ...\n",
    "\n",
    "\n",
    "### Task 6: Analyzing Income Based on Relationships\n",
    "\n",
    "This task employs Seaborn's catplot to create a bar chart comparing income levels ('income') with different types of relationships ('relationship') within the 'df' dataset. This visualization aims to understand how income varies concerning various relationships, offering insights into potential income differences among different relationship statuses in the US Census adult income data analysis.\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 2 TASK 6 ---\n",
    "catplt_relat = ...\n",
    "\n",
    "\n",
    "### Task 7: Analyzing Income Based on Gender\n",
    "\n",
    "This task utilizes Seaborn's catplot to create a bar chart comparing income levels ('income') based on gender ('sex') within the 'df' dataset. This visualization aims to understand how income levels differ between genders, providing insights into potential income disparities based on gender in the US Census adult income data analysis.\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 2 TASK 7 ---\n",
    "catplt_sex = ...\n",
    "\n",
    "\n",
    "### Task 8: Analyzing Income Based on Marital Status\n",
    "This task employs Seaborn's catplot to create a bar chart comparing income levels ('income') based on marital status ('marital.status') within the 'df' dataset. This visualization aims to understand how income levels differ across different marital statuses, providing insights into potential income disparities related to marital status in the US Census adult income data analysis.\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 2 TASK 8 ---\n",
    "catplt_married  = ...\n",
    "\n",
    "\n",
    "### Task 9: Analyzing Income Based on Workclass\n",
    "\n",
    "In this task, Seaborn's catplot is used to create a bar chart comparing income levels ('income') based on different work classes ('workclass') within the 'df' dataset. This visualization aims to understand how income levels differ across various work classes, providing insights into potential income disparities related to different employment categories in the US Census adult income data analysis.\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 2 TASK 9 ---\n",
    "catplt_wrkcls  = ...\n",
    "\n",
    "## Module 3\n",
    "### Task 1: Data Preprocessing for Relationship and Gender\n",
    "\n",
    "This task involves creating a modified 'data' DataFrame by encoding the 'sex' attribute from strings 'Male' and 'Female' to numerical values 0 and 1, respectively. Furthermore, it consolidates the 'marital.status' attribute into two categories 'Married' and 'Single' for improved analysis and replaces these categories with binary values 1 and 0, respectively. This preprocessing is vital for refining and simplifying the relationship and gender attributes to enhance the accuracy and interpretability of the data for further analysis in the US Census adult income data.\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 3 TASK 1 ---\n",
    "data  = ...\n",
    "\n",
    "### Task 2: Removing Certain Attributes for Data Simplification\n",
    "\n",
    "This task involves dropping specific columns, including \"workclass\", \"education\", \"occupation\", \"relationship\", \"race\", and \"native.country\" from the 'data' DataFrame. The removal of these columns simplifies the dataset by eliminating non-essential or redundant attributes, focusing the analysis on the more relevant features for the US Census adult income data analysis.\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 3 TASK 2 ---\n",
    "#data  = ...\n",
    "\n",
    "## Module 4\n",
    "### Task 1: Data Splitting for Modeling in Adult Income Data\n",
    "\n",
    "This task involves splitting the 'data' DataFrame into training and validation sets for modeling. The feature set 'x' is generated by dropping the 'income' column, while the target variable 'y' consists solely of the 'income' column. Utilizing the train_test_split function from sklearn.model_selection, the data is split into 80% training data ('X_train' and 'Y_train') and 20% validation data ('X_validation' and 'Y_validation'). This step is essential for training and evaluating models in the US Census adult income data analysis.\n",
    "\n",
    "#--- Import train_test_split ---\n",
    "# --- WRITE YOUR CODE FOR MODULE 4 TASK 1 ---\n",
    "#X_train, X_validation, Y_train, Y_validation  = ...\n",
    "\n",
    "#--- Inspect data ---\n",
    "\n",
    "### Task 2: Training and Evaluating Logistic Regression Model\n",
    "\n",
    "This task involves training a Logistic Regression model using the training data 'X_train' and 'Y_train' and then assessing the model's performance using cross-validation with 10 folds. The cross_val_score function from sklearn.model_selection assesses the Logistic Regression model's performance and computes the mean accuracy score over the 10 folds. This evaluation is crucial for understanding the model's predictive capability in the US Census adult income data analysis.\n",
    "\n",
    "#--- Import LogisticRegression ---\n",
    "#--- Import cross_val_score from sklearn.model_selection ---\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 4 TASK 2 ---\n",
    "#lr_mean_score  = ...\n",
    "\n",
    "#--- Inspect data ---\n",
    "\n",
    "### Task 3: Training and Evaluating Linear Discriminant Analysis Model\n",
    "\n",
    "This task involves training a Linear Discriminant Analysis (LDA) model using the training data 'X_train' and 'Y_train' and then assessing the model's performance via 10-fold cross-validation. The cross_val_score function from sklearn.model_selection is used to evaluate the LDA model's accuracy across the 10 folds. This evaluation is vital for understanding the model's performance in predicting income classes within the US Census adult income data analysis.\n",
    "\n",
    "#--- Import LinearDiscriminantAnalysis ---\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 4 TASK 3 ---\n",
    "#ldr_mean_score  = ...\n",
    "\n",
    "#--- Inspect data ---\n",
    "\n",
    "### Task 4: Training and Evaluating K-Nearest Neighbors Classifier\n",
    "\n",
    "This task involves training a K-Nearest Neighbors (KNN) classification model using the training data 'X_train' and 'Y_train'. Subsequently, the model's performance is assessed by utilizing the cross_val_score function from sklearn.model_selection, evaluating the KNN model's accuracy across 10-fold cross-validation. This evaluation is important to gauge the KNN model's predictive performance in determining income classes within the US Census adult income data analysis.\n",
    "\n",
    "#--- Import KNeighborsClassifier ---\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 4 TASK 4 ---\n",
    "#knn_mean_score  = ...\n",
    "\n",
    "#--- Inspect data ---\n",
    "\n",
    "### Task 5: Training and Evaluating Decision Tree Classifier\n",
    "\n",
    "This task involves training a Decision Tree Classifier using the training data 'X_train' and 'Y_train', followed by assessing the model's performance through 10-fold cross-validation. The cross_val_score function from sklearn.model_selection is used to compute the Decision Tree Classifier's mean accuracy across the 10 folds. This evaluation is crucial for understanding the Decision Tree model's performance in predicting income classes within the US Census adult income data analysis.\n",
    "\n",
    "#--- Import DecisionTreeClassifier ---\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 4 TASK 5 ---\n",
    "#dt_mean_score  = ...\n",
    "\n",
    "#--- Inspect data ---\n",
    "\n",
    "### Task 6: Training and Evaluating Gaussian Naive Bayes Classifier\n",
    "\n",
    "This task involves training a Gaussian Naive Bayes (NB) classifier using the training data 'X_train' and 'Y_train', followed by assessing the model's performance via 10-fold cross-validation. The cross_val_score function from sklearn.model_selection is utilized to determine the Gaussian NB model's mean accuracy across the 10 folds. This evaluation is essential for comprehending the model's predictive performance in determining income classes within the US Census adult income data analysis.\n",
    "\n",
    "#--- Import GaussianNB ---\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 4 TASK 6 ---\n",
    "#gb_mean_score   = ...\n",
    "\n",
    "#--- Inspect data ---\n",
    "\n",
    "### Task 7: Model Optimization using GridSearchCV\n",
    "\n",
    "In this task, GridSearchCV from sklearn.model_selection is utilized to optimize the Linear Discriminant Analysis (LDA) model's performance. The parameters for 'solver' are specified as 'svd', 'lsqr', and 'eigen'. GridSearchCV performs a search across the defined parameters within a 5-fold cross-validation setup using the training data ('X_train' and 'Y_train'). After the grid search, 'best_params' capture the most optimal parameters, and 'best_score' denotes the highest achieved score among the parameter combinations. Additionally, the 'best_ldr_model' variable holds the optimized LDA model with the best parameters obtained from the grid search, enhancing the model's performance within the US Census adult income data analysis.\n",
    "\n",
    "#--- Import GridSearchCV ---\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 4 TASK 7 ---\n",
    "#best_score   = ...\n",
    "\n",
    "#--- Inspect data ---\n",
    "\n",
    "### Task 8: Evaluating Model Performance on Validation Data\n",
    "\n",
    "This task involves evaluating the performance of the selected model, identified from previous training assessments, using the validation dataset 'X_validation' and 'Y_validation'. The accuracy_score function from sklearn.metrics determines the accuracy by comparing the predicted values ('y_pred') to the actual values ('Y_validation'). Additionally, the confusion_matrix and classification_report functions from sklearn.metrics are used to generate a confusion matrix and a comprehensive classification report, respectively. These metrics provide insights into the model's predictive accuracy and misclassifications, aiding in assessing the model's performance in predicting income classes within the US Census adult income data analysis.\n",
    "\n",
    "#--- Import accuracy_score, confusion_matrix, classification_report from sklearn.metrics ---\n",
    "\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 4 TASK 8 ---\n",
    "accuracy= ...\n",
    "\n",
    "cm= ...\n",
    "\n",
    "cr= ...\n",
    "\n",
    "#--- Inspect data ---\n",
    "\n",
    "### Task 9: Evaluating Precision, Recall, and F1-Score\n",
    "\n",
    "This task calculates the precision, recall, and F1-score metrics for the model using the validation dataset. The precision_score, recall_score, and f1_score functions from sklearn.metrics are employed to compute precision, recall, and the F1-score, respectively. These metrics offer insights into the model's precision (accuracy of positive predictions), recall (sensitivity to actual positives), and the balance between precision and recall captured by the F1-score. These calculations further aid in understanding the model's performance in predicting income classes within the US Census adult income data analysis.\n",
    "\n",
    "#--- Import precision_score, recall_score, f1_score from sklearn.metrics ---\n",
    "\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 4 TASK 9 ---\n",
    "# Calculate precision\n",
    "precision = ...\n",
    "\n",
    "# Calculate recall\n",
    "recall = ...\n",
    "\n",
    "# Calculate F1-score\n",
    "F1_score = ...\n",
    "\n",
    "\n",
    "#precision,recall,F1_score\n",
    "\n",
    "#--- Inspect data ---\n",
    "\n",
    "### Task 10: Predicting Income Class on New Data\n",
    "\n",
    "This task involves utilizing the best-performing model determined from prior evaluations to predict the income class for new data. The new data, structured as a NumPy array, comprises features related to an individual's characteristics, such as age, fnlwgt, education years, among others. The model (which needs to be replaced by the specific best model selected previously) predicts the income class based on these features. The 'predict' method applies the model to the new data to generate the predicted income class, aiding in understanding how accurately the model can predict income status for a new individual in the context of the US Census adult income data analysis.\n",
    "\n",
    "# --- WRITE YOUR CODE FOR MODULE 4 TASK 10 ---\n",
    "#You need to predict the result by passing the sample data available here to your model to make a prediction.\n",
    "\n",
    "new_data = pd.DataFrame([[74, 88638, 16, 0, 1, 0, 683, 20]],\n",
    "                    columns=['age', 'fnlwgt', 'education.num', 'marital.status', 'sex', 'capital.gain', 'capital.loss', 'hours.per.week'])\n",
    "prediction = ...\n",
    "\n",
    "#--- Inspect data ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
